{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tutorial of Pytff\n",
    "\n",
    "First lets import the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytff\n",
    "import pytff.datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Command 'path/to/tff'> -> /tmp/tmpmSHAWa_tff"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff = pytff.TFFCommand(tff_path=\"path/to/tff\")\n",
    "tff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main method of `TFFCommand` instance is **analize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method analyze in module pytff.core:\n",
      "\n",
      "analyze(self, periods, times, values, ntbin=300, nmin=10, mindp=10, snr1min=10.0, nmatch=10, dph=1e-05, asig=555.0, jfit=-1) method of pytff.core.TFFCommand instance\n",
      "    Run the tff analysis.\n",
      "    \n",
      "    Params\n",
      "    ------\n",
      "    \n",
      "    periods: 1d-array-like\n",
      "        An array with all the periods of the sources.\n",
      "    times: 2d-array-like\n",
      "        Every row represents all the times of one source\n",
      "    values: 2d-array-like\n",
      "        Every row represents all the magnitudes of one source\n",
      "    ntbin: int\n",
      "        number of bins of the templates (default: 300)\n",
      "    nmin: int\n",
      "        minimum number of the template data points (default: 10)\n",
      "    mindp: int\n",
      "        minimum number of the target data points (default: 10)\n",
      "    snr1min: float\n",
      "        minimum SNR1 of the template time series (default: 10.0)\n",
      "    nmatch: int\n",
      "        number of the top best matching templates to be printed\n",
      "        (default: 10)\n",
      "    dph: float\n",
      "        templates are fitted with dph accuracy in phase (default: 0.00001)\n",
      "    asig: float\n",
      "        sigma clipping parameter for template and Fourier fits\n",
      "        (default: 555.0)\n",
      "    jfit: int\n",
      "        template polynomial degree (if jfit < 0, then optimized)\n",
      "        (default: -1)\n",
      "    \n",
      "    The i-nth row of times must be has the same number of values i-nth row\n",
      "    of values.\n",
      "    \n",
      "    Return\n",
      "    ------\n",
      "    \n",
      "    tff_data: ndarray\n",
      "        Fourier decompositions, resulting from the TFF analysis.\n",
      "        Fields:\n",
      "    \n",
      "        -   **src_idx:** In which index of periods, times and values is\n",
      "            the data used for generate this fourier decomposition.\n",
      "        -   **period:** The perdiod\n",
      "        -   **epoch:** The epoch\n",
      "        -   **average_magnitude:** average of values\n",
      "        -   **N_data_point:** Size of time and value\n",
      "        -   **sigma_obs_fit:** std deviation\n",
      "        -   **A_1, phi_1, A_2, phi_2, ..., A_15, phi_15** The fourier\n",
      "            components\n",
      "    \n",
      "        Form of the Fourier decomposition:\n",
      "    \n",
      "        ::\n",
      "    \n",
      "            A_0 + A_1*sin(2*pi*(t(i)-Epoch)*1/Period+Phi_1)\n",
      "                  A_2*sin(2*pi*(t(i)-Epoch)*2/Period+Phi_2) +\n",
      "                  A_3*sin(2*pi*(t(i)-Epoch)*3/Period+Phi_3) + ...\n",
      "    \n",
      "    dff_data: ndarray\n",
      "        Fourier decompositions, resulting from the DFF analysis.\n",
      "        Same fields as *tff_data*\n",
      "    \n",
      "    match_data: ndarray\n",
      "        List of target/template matches. You gona have ``nmatch`` rows for\n",
      "        every source.\n",
      "        Fields:\n",
      "    \n",
      "        -   **src_idx:** In which index of periods, times and values is\n",
      "            the data used for generate this match.\n",
      "        -   **match_rank:** value in between 1 and nmatch that represent\n",
      "            the importance of this match with the source (lower is better)\n",
      "        -   **src_period:** The period of the source.\n",
      "        -   **src_sigma_obs_fit:** std deviation of the source.\n",
      "        -   **order_of_the_template**\n",
      "        -   **snr:** is the signal-to-noise ratio of the template-fitted\n",
      "            light curve. ``SNR=AMP/(sigma/sqrt(n))``, where 'AMP' is the\n",
      "            total amplitude of the best fitting template, 'sigma' is the\n",
      "            standard deviation of the residuals between the target and\n",
      "            the template, 'n' is the number of the target data points.\n",
      "        -   **template_id**\n",
      "        -   **template_period**\n",
      "        -   **template_sigma_obs_fit:** std deviation of the templates.\n",
      "        -   **src_N_data_point:** Size of time and value.\n",
      "        -   **template_phi_31**\n",
      "    \n",
      "    For more info please see:\n",
      "    http://www.konkoly.hu/staff/kovacs/tff_in_out.inf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tff.analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake Example\n",
    "\n",
    "Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "periods = np.random.rand(10)\n",
    "times = np.random.rand(10, 50)\n",
    "values = np.random.rand(*times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tff_data, dff_data, match_data = tff.analyze(periods, times, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 'M5 V77'), (0, 'M5 V87'), (0, 'oCen V206'), (0, 'M3 V124'),\n",
       "       (0, 'FW Lup'), (0, 'M3 V62'), (0, 'M2 V10'), (0, 'oCen V170'),\n",
       "       (0, 'Rup106 V13'), (0, 'M5 V75'), (1, 'FW Lup'), (1, 'M3 V62'),\n",
       "       (1, 'M3 V124'), (1, 'M5 V87'), (1, 'Rup106 V18'), (1, 'M68 V30'),\n",
       "       (1, 'M5 V75'), (1, 'Rup106 V16'), (1, 'M5 V77'), (1, 'Rup106 V13'),\n",
       "       (2, 'M5 V87'), (2, 'M3 V124'), (2, 'FW Lup'), (2, 'Rup106 V13'),\n",
       "       (2, 'M68 V30'), (2, 'Rup106 V18'), (2, 'M3 V62'), (2, 'CN Lyr'),\n",
       "       (2, 'M5 V75'), (2, 'Rup106 V16'), (3, 'M3 V124'), (3, 'M5 V87'),\n",
       "       (3, 'Rup106 V18'), (3, 'M68 V30'), (3, 'FW Lup'), (3, 'Rup106 V13'),\n",
       "       (3, 'M3 V62'), (3, 'Rup106 V16'), (3, 'M5 V75'), (3, 'Rup106 V1'),\n",
       "       (4, 'M5 V87'), (4, 'M3 V124'), (4, 'FW Lup'), (4, 'M3 V62'),\n",
       "       (4, 'M68 V30'), (4, 'Rup106 V13'), (4, 'Rup106 V18'), (4, 'M5 V75'),\n",
       "       (4, 'M5 V77'), (4, 'Rup106 V16'), (5, 'M5 V87'), (5, 'M3 V124'),\n",
       "       (5, 'Rup106 V13'), (5, 'FW Lup'), (5, 'M68 V30'), (5, 'Rup106 V18'),\n",
       "       (5, 'M3 V62'), (5, 'Rup106 V16'), (5, 'CN Lyr'), (5, 'M5 V75'),\n",
       "       (6, 'M5 V87'), (6, 'M3 V124'), (6, 'FW Lup'), (6, 'Rup106 V18'),\n",
       "       (6, 'M68 V30'), (6, 'Rup106 V13'), (6, 'M3 V62'), (6, 'Rup106 V16'),\n",
       "       (6, 'M5 V75'), (6, 'M5 V77'), (7, 'M5 V87'), (7, 'M3 V124'),\n",
       "       (7, 'Rup106 V13'), (7, 'M68 V30'), (7, 'Rup106 V18'), (7, 'FW Lup'),\n",
       "       (7, 'M3 V62'), (7, 'Rup106 V16'), (7, 'CN Lyr'), (7, 'M5 V75'),\n",
       "       (8, 'M3 V124'), (8, 'M5 V87'), (8, 'FW Lup'), (8, 'M68 V30'),\n",
       "       (8, 'Rup106 V18'), (8, 'M3 V62'), (8, 'Rup106 V13'),\n",
       "       (8, 'Rup106 V16'), (8, 'M5 V75'), (8, 'CN Lyr'), (9, 'M5 V87'),\n",
       "       (9, 'M3 V124'), (9, 'FW Lup'), (9, 'M68 V30'), (9, 'Rup106 V13'),\n",
       "       (9, 'Rup106 V18'), (9, 'M3 V62'), (9, 'Rup106 V16'), (9, 'M5 V75'),\n",
       "       (9, 'oCen V206')], \n",
       "      dtype=[('src_idx', '<i8'), ('template_id', 'S255')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_data[[\"src_idx\", \"template_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data Example\n",
    "\n",
    "Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data Example\n",
    "\n",
    "Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2088.91535,    18.868  ],\n",
       "       [ 2090.87535,    19.54   ],\n",
       "       [ 2103.92958,    18.704  ],\n",
       "       ..., \n",
       "       [ 4853.56146,    19.116  ],\n",
       "       [ 4854.56497,    18.974  ],\n",
       "       [ 4864.5617 ,    18.835  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(ds.get(\"single\", \"ogle.dat\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Reformat the data for pytff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this value is the real period of this star (i don't remember the original id\n",
    "# is necesary to create an array of one element for only one star\n",
    "periods = np.array([0.6347522])\n",
    "\n",
    "# convert the first column of the data into a first row of the 2d array\n",
    "times = data[:,0].reshape(1, len(data[:,0]))\n",
    "\n",
    "# convert the second column of the data into a first row of the 2d array\n",
    "values = data[:,1].reshape(1, len(data[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tff_data, dff_data, match_data = tff.analyze(periods, times, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (0, 0.63475, 0.0, 19.034, 654.0, 0.2288, 0.1481, 4.1906, 0.0493, 4.8528, 0.0192, 5.9558, 0.005, 1.1047, 0.0043, 2.6569, 0.0049, 3.4054, 0.0036, 4.5121, 0.0034, 5.5922, 0.0017, 0.0709, 0.0015, 0.5639, 0.0, 0.2353, 0.0, 0.0276, 0.0, 0.0846, 0.0, 3.8838, 0.0, 0.6126)], \n",
       "      dtype=[('src_idx', '<i8'), ('period', '<f8'), ('epoch', '<f8'), ('average_magnitude', '<f8'), ('N_data_point', '<f8'), ('sigma_obs_fit', '<f8'), ('A_1', '<f8'), ('phi_1', '<f8'), ('A_2', '<f8'), ('phi_2', '<f8'), ('A_3', '<f8'), ('phi_3', '<f8'), ('A_4', '<f8'), ('phi_4', '<f8'), ('A_5', '<f8'), ('phi_5', '<f8'), ('A_6', '<f8'), ('phi_6', '<f8'), ('A_7', '<f8'), ('phi_7', '<f8'), ('A_8', '<f8'), ('phi_8', '<f8'), ('A_9', '<f8'), ('phi_9', '<f8'), ('A_10', '<f8'), ('phi_10', '<f8'), ('A_11', '<f8'), ('phi_11', '<f8'), ('A_12', '<f8'), ('phi_12', '<f8'), ('A_13', '<f8'), ('phi_13', '<f8'), ('A_14', '<f8'), ('phi_14', '<f8'), ('A_15', '<f8'), ('phi_15', '<f8')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.63475, 0.0, 19.034, 654.0, 0.2288, 0.1481, 4.1906, 0.0493, 4.8528, 0.0192, 5.9558, 0.005, 1.1047, 0.0043, 2.6569, 0.0049, 3.4054, 0.0036, 4.5121, 0.0034, 5.5922, 0.0017, 0.0709, 0.0015, 0.5639, 0.0, 0.2353, 0.0, 0.0276, 0.0, 0.0846, 0.0, 3.8838, 0.0, 0.6126)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff_data[0] # our first and only source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63475])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tff_data[\"period\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (0, 1, 0.63475, 0.2288, 0, 9.5541, 'M3 V124', 0.75243, 0.2288, 654, 5.9504),\n",
       "       (0, 2, 0.63475, 0.2288, 0, 9.5541, 'M5 V87', 0.73921, 0.2299, 654, 6.0107),\n",
       "       (0, 3, 0.63475, 0.2288, 0, 9.5541, 'Rup106 V13', 0.65315, 0.2345, 654, 4.9328),\n",
       "       (0, 4, 0.63475, 0.2288, 0, 9.5541, 'FW Lup', 0.48417, 0.2347, 654, 5.7156),\n",
       "       (0, 5, 0.63475, 0.2288, 0, 9.5541, 'M68 V30', 0.73364, 0.235, 654, 5.3584),\n",
       "       (0, 6, 0.63475, 0.2288, 0, 9.5541, 'Rup106 V18', 0.63547, 0.2383, 654, 5.4264),\n",
       "       (0, 7, 0.63475, 0.2288, 0, 9.5541, 'M3 V62', 0.65241, 0.2464, 654, 5.6235),\n",
       "       (0, 8, 0.63475, 0.2288, 0, 9.5541, 'Rup106 V16', 0.62851, 0.2501, 654, 5.2816),\n",
       "       (0, 9, 0.63475, 0.2288, 0, 9.5541, 'CN Lyr', 0.41138, 0.2563, 654, 5.5319),\n",
       "       (0, 10, 0.63475, 0.2288, 0, 9.5541, 'M5 V75', 0.68547, 0.2574, 654, 5.6388)], \n",
       "      dtype=[('src_idx', '<i8'), ('match_rank', '<i8'), ('src_period', '<f8'), ('src_sigma_obs_fit', '<f8'), ('order_of_the_template', '<i8'), ('snr', '<f8'), ('template_id', 'S255'), ('template_period', '<f8'), ('template_sigma_obs_fit', '<f8'), ('src_N_data_point', '<i8'), ('template_phi_31', '<f8')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
